# app.py - GRIND 15000: La IA Entrenadora Humana Completa
# "El grind no es sufrimiento. Es elecci√≥n."
# Creador: Eliezer Mesac Feliz Luciano
# Fecha: 2025
# Inspirado en ChatGPT, pero con fuego real.
# Versi√≥n: 14.0 - Super Completa, Extensa, Funcional, +10000 l√≠neas

try:
    import sys
    import pysqlite3
    sys.modules["sqlite3"] = sys.modules.pop("pysqlite3")
except (ImportError, KeyError):
    pass

import streamlit as st
import os
import json
import random
import requests
import time
import re
import subprocess
from datetime import datetime, timedelta
from typing import Dict, Any, List, Callable
from functools import wraps
from dotenv import load_dotenv
import tiktoken
import random  
from streamlit import secrets
# --- PARA CARGA DE DOCUMENTOS ---
try:
    import PyPDF2
    from docx import Document
except ImportError:
    PyPDF2 = None
    Document = None
    print("[WARNING] PyPDF2 o python-docx no instalados. Funci√≥n de carga de documentos deshabilitada.")
# --- PARA VOZ (TTS) ---
from gtts import gTTS
from io import BytesIO
# --- PARA MEMORIA A LARGO PLAZO (FAISS + Embeddings) ---
try:
    from sentence_transformers import SentenceTransformer
    import faiss
    import numpy as np
except ImportError:
    SentenceTransformer = None
    faiss = None
    np = None
    print("[WARNING] sentence-transformers o faiss no instalados. Memoria a largo plazo deshabilitada.")

load_dotenv()

# === CARGAR VARIABLES DE ENTORNO ===
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")
SERPAPI_API_KEY = os.getenv("SERPAPI_API_KEY", "")
SUPABASE_URL = os.getenv("SUPABASE_URL", "")
SUPABASE_KEY = os.getenv("SUPABASE_KEY", "")
HF_TOKEN = os.getenv("HF_TOKEN", "")

# Paths del proyecto
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(PROJECT_ROOT, "data")
MODELS_DIR = os.path.join(PROJECT_ROOT, "modelos")

# Asegurar carpetas
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(os.path.join(DATA_DIR, "habitos"), exist_ok=True)
os.makedirs(os.path.join(DATA_DIR, "chats"), exist_ok=True)
os.makedirs(os.path.join(DATA_DIR, "memoria"), exist_ok=True)
os.makedirs(os.path.join(DATA_DIR, "niveles"), exist_ok=True)
os.makedirs(os.path.join(DATA_DIR, "autoevaluacion"), exist_ok=True)
os.makedirs(os.path.join(DATA_DIR, "recordatorios"), exist_ok=True)
os.makedirs(os.path.join(DATA_DIR, "backup"), exist_ok=True)
os.makedirs(os.path.join(DATA_DIR, "notion"), exist_ok=True)
os.makedirs(os.path.join(DATA_DIR, "google"), exist_ok=True)
os.makedirs(os.path.join(DATA_DIR, "fuentes"), exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)

# --- FUNCIONES DE UTILIDAD ---
def manejar_error(mensaje: str, error: Exception = None):
    """Registra errores de forma limpia y muestra un mensaje de fallback."""
    if error:
        print(f"[ERROR] {mensaje}: {str(error)}")
    else:
        print(f"[ERROR] {mensaje}")

def fallback_si_falla(func: Callable) -> Callable:
    """Decorador: si una funci√≥n falla, devuelve un mensaje de respaldo."""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            manejar_error(f"Error en {func.__name__}", e)
            return "No tengo la respuesta perfecta ahora. Pero s√© esto: no est√°s solo. El grind no es sufrimiento. Es elecci√≥n."
    return wrapper

def cargar_json(ruta: str) -> dict:
    """Carga un archivo JSON de forma segura. Si no existe, devuelve un diccionario vac√≠o."""
    try:
        if os.path.exists(ruta):
            with open(ruta, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            print(f"[WARNING] Archivo no encontrado: {ruta}")
            return {}
    except Exception as e:
        print(f"[ERROR] No se pudo cargar {ruta}: {e}")
        return {}
    def construir_contexto_conversacional(historial: list, max_tokens: int = 2048) -> str:
     """Construye un contexto de conversaci√≥n coherente, respetando l√≠mite de tokens."""
    encoder = tiktoken.encoding_for_model("gpt-3.5-turbo")  # Funciona bien para la mayor√≠a de modelos
    contexto = ""
    tokens_usados = 0
    
    for msg in reversed(historial):
        parte = f"{msg['role'].upper()}: {msg['content']}\n"
        tokens_parte = len(encoder.encode(parte))
        
        if tokens_usados + tokens_parte > max_tokens:
            break
            
        contexto = parte + contexto
        tokens_usados += tokens_parte
        
    return contexto.strip()

def detectar_herramienta_necesaria(prompt: str) -> str:
    """Detecta qu√© herramienta necesita el usuario seg√∫n su pregunta."""
    prompt_lower = prompt.lower()
    if any(p in prompt_lower for p in ["busca", "qu√© es", "define", "noticias", "actualidad", "√∫ltimas noticias", "c√≥mo funciona"]):
        return "buscar_en_web"
    elif any(p in prompt_lower for p in ["calcula", "cu√°nto es", "matem√°ticas", "f√≥rmula", "ecuaci√≥n", "resuelve", "+", "-", "*", "/"]):
        return "calculadora"
    elif any(p in prompt_lower for p in ["traduce", "traducci√≥n", "en ingl√©s", "en espa√±ol", "en franc√©s", "en alem√°n", "significa"]):
        return "traductor"
    else:
        return "chat"

    def groq_llamada(prompt: str, historial: list) -> str:
     """Llama a la API de Groq con el modelo Llama 3."""
    try:
        from groq import Groq
        client = Groq(api_key=secrets["GROQ_API_KEY"])
        mensajes = [{"role": "system", "content": "Eres GRIND, una entrenadora de vida directa y motivadora."}]
        # A√±adir historial
        for msg in historial[-5:]:  # √öltimos 5 mensajes
            mensajes.append({"role": msg["role"], "content": msg["content"]})
        # A√±adir pregunta actual
        mensajes.append({"role": "user", "content": prompt})
        # Llamar a Groq
        chat_completion = client.chat.completions.create(
            messages=mensajes,
            model="llama3-8b-8192",
            temperature=0.7,
            max_tokens=512
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        manejar_error("Groq API", e)
        return "No pude conectar con Groq. Pero t√∫ s√≠ puedes elegir: act√∫a."

def calcular(prompt: str) -> str:
    """Calcula expresiones matem√°ticas simples de forma segura."""
    import re
    # Extraer solo n√∫meros, operadores b√°sicos y par√©ntesis
    safe_expr = re.sub(r'[^0-9+\-*/(). ]', '', prompt)
    try:
        # Evaluar de forma segura (¬°solo para demo! En producci√≥n usa `asteval` o `sympy`)
        resultado = eval(safe_expr, {"__builtins__": {}})
        return f"üßÆ Resultado: {resultado}"
    except Exception:
        return "‚ö†Ô∏è No pude calcular eso. Intenta con una operaci√≥n simple como '2 + 2'."

def traducir_texto(prompt: str) -> str:
    """Traduce texto usando deep-translator (estable y sin conflictos)."""
    try:
        from deep_translator import GoogleTranslator, single_detection
        
        # Detectar idioma de origen
        origen = single_detection(prompt, api_key=None)  # Usa detecci√≥n local
        destinos = {
            "en ingl√©s": "en",
            "en espa√±ol": "es",
            "en franc√©s": "fr",
            "en alem√°n": "de",
            "en portugu√©s": "pt",
            "en italiano": "it"
        }
        
        # Detectar idioma destino
        destino = "en"  # por defecto
        for frase, lang in destinos.items():
            if frase in prompt.lower():
                destino = lang
                break
        
        if origen == destino:
            return "‚ö†Ô∏è El texto ya est√° en ese idioma."
            
        # Traducir
        translator = GoogleTranslator(source=origen, target=destino)
        traduccion = translator.translate(prompt)
        return f"üåç Traducci√≥n ({origen} ‚Üí {destino}): {traduccion}"
    except Exception as e:
        return f"‚ö†Ô∏è Error al traducir: {str(e)}. Prueba m√°s tarde."

def ejecutar_herramienta(herramienta: str, prompt: str) -> str:
    """Ejecuta la herramienta seleccionada y devuelve el resultado."""
    if herramienta == "buscar_en_web":
        return buscar_en_web(prompt)
    elif herramienta == "calculadora":
        return calcular(prompt)
    elif herramienta == "traductor":
        return traducir_texto(prompt)
    else:
        return prompt  # Solo chat# üëáüëáüëá PEGA ESTO DESPU√âS DE construir_contexto_conversacional

def detectar_herramienta_necesaria(prompt: str) -> str:
    """Detecta qu√© herramienta necesita el usuario seg√∫n su pregunta."""
    prompt_lower = prompt.lower()
    if any(p in prompt_lower for p in ["busca", "qu√© es", "define", "noticias", "actualidad", "√∫ltimas noticias", "c√≥mo funciona"]):
        return "buscar_en_web"
    elif any(p in prompt_lower for p in ["calcula", "cu√°nto es", "matem√°ticas", "f√≥rmula", "ecuaci√≥n", "resuelve", "+", "-", "*", "/"]):
        return "calculadora"
    elif any(p in prompt_lower for p in ["traduce", "traducci√≥n", "en ingl√©s", "en espa√±ol", "en franc√©s", "en alem√°n", "significa"]):
        return "traductor"
    else:
        return "chat"

def calcular(prompt: str) -> str:
    """Calcula expresiones matem√°ticas simples de forma segura."""
    import re
    # Extraer solo n√∫meros, operadores b√°sicos y par√©ntesis
    safe_expr = re.sub(r'[^0-9+\-*/(). ]', '', prompt)
    try:
        # Evaluar de forma segura (¬°solo para demo! En producci√≥n usa `asteval` o `sympy`)
        resultado = eval(safe_expr, {"__builtins__": {}})
        return f"üßÆ Resultado: {resultado}"
    except Exception:
        return "‚ö†Ô∏è No pude calcular eso. Intenta con una operaci√≥n simple como '2 + 2'."

def traducir_texto(prompt: str) -> str:
    """Traduce texto usando deep-translator (estable y sin conflictos)."""
    try:
        from deep_translator import GoogleTranslator, single_detection
        # Detectar idioma de origen
        origen = single_detection(prompt, api_key=None)  # Usa detecci√≥n local
        destinos = {
            "en ingl√©s": "en",
            "en espa√±ol": "es",
            "en franc√©s": "fr",
            "en alem√°n": "de",
            "en portugu√©s": "pt",
            "en italiano": "it"
        }
        # Detectar idioma destino
        destino = "en"  # por defecto
        for frase, lang in destinos.items():
            if frase in prompt.lower():
                destino = lang
                break
        if origen == destino:
            return "‚ö†Ô∏è El texto ya est√° en ese idioma."
        # Traducir
        translator = GoogleTranslator(source=origen, target=destino)
        traduccion = translator.translate(prompt)
        return f"üåç Traducci√≥n ({origen} ‚Üí {destino}): {traduccion}"
    except Exception as e:
        return f"‚ö†Ô∏è Error al traducir: {str(e)}. Prueba m√°s tarde."

def ejecutar_herramienta(herramienta: str, prompt: str) -> str:
    """Ejecuta la herramienta seleccionada y devuelve el resultado."""
    if herramienta == "buscar_en_web":
        return buscar_en_web(prompt)
    elif herramienta == "calculadora":
        return calcular(prompt)
    elif herramienta == "traductor":
        return traducir_texto(prompt)
    else:
        return prompt  # Solo chat

def detectar_idioma(texto: str) -> str:
    """Detecta el idioma del usuario por palabras clave."""
    texto = texto.lower().strip()
    if any(p in texto for p in ["hola", "gracias", "por favor", "necesito", "cansado", "quiero morir"]):
        return "espa√±ol"
    elif any(p in texto for p in ["hello", "thanks", "please", "need", "tired", "want to die"]):
        return "english"
    elif any(p in texto for p in ["merci", "bonjour", "s'il vous pla√Æt", "fatigu√©", "je veux mourir"]):
        return "fran√ßais"
    elif any(p in texto for p in ["hallo", "danke", "bitte", "m√ºde", "ich will sterben"]):
        return "deutsch"
    elif any(p in texto for p in ["ol√°", "obrigado", "por favor", "preciso", "cansado", "quero morrer"]):
        return "portugu√™s"
    elif any(p in texto for p in ["bon dia", "gr√†cies", "si us plau", "estic cansat", "vull morir"]):
        return "catal√†"
    elif any(p in texto for p in ["kaixo", "eskerrik asko", "mesedez", "behar dut", "ezin dut", "hil nahi dut"]):
        return "euskera"
    elif any(p in texto for p in ["ciao", "grazie", "per favore", "ho bisogno", "stanco", "voglio morire"]):
        return "italiano"
    elif any(p in texto for p in ["„Åì„Çì„Å´„Å°„ÅØ", "„ÅÇ„Çä„Åå„Å®„ÅÜ", "„ÅäÈ°ò„ÅÑ„Åó„Åæ„Åô", "Áñ≤„Çå„Åü", "Ê≠ª„Å´„Åü„ÅÑ"]):
        return "japon√©s"
    elif any(p in texto for p in ["‰Ω†Â•Ω", "Ë∞¢Ë∞¢", "ËØ∑", "Á¥Ø‰∫Ü", "ÊÉ≥Ê≠ª"]):
        return "chino"
    elif any(p in texto for p in ["ŸÖÿ±ÿ≠ÿ®ÿß", "ÿ¥ŸÉÿ±ÿß", "ŸÖŸÜ ŸÅÿ∂ŸÑŸÉ", "ÿ™ÿπÿ®ÿ™", "ÿ£ÿ±ŸäÿØ ÿ£ŸÜ ÿ£ŸÖŸàÿ™"]):
        return "√°rabe"
    else:
        return "espa√±ol"

        # --- VOZ: TEXTO A HABLA ---
def reproducir_voz(texto: str, idioma: str = "es") -> bytes:
    """Convierte texto a audio MP3 usando Google TTS."""
    try:
        # Mapear idiomas soportados por GRIND a c√≥digos de gTTS
        lang_map = {
            "espa√±ol": "es",
            "english": "en",
            "fran√ßais": "fr",
            "deutsch": "de",
            "portugu√™s": "pt",
            "catal√†": "ca",
            "euskera": "eu",
            "italiano": "it",
            "japon√©s": "ja",
            "chino": "zh-CN",
            "√°rabe": "ar"
        }
        lang_code = lang_map.get(idioma, "es")  # Por defecto espa√±ol
        tts = gTTS(text=texto, lang=lang_code, slow=False)
        mp3_fp = BytesIO()
        tts.write_to_fp(mp3_fp)
        return mp3_fp.getvalue()
    except Exception as e:
        manejar_error("Voz (TTS)", e)
        return None

def formatear_respuesta(texto: str, nombre: str = "Usuario") -> str:
    """A√±ade estilo, met√°foras y personalidad de GRIND a cualquier respuesta."""
    inicio = f"üî• {nombre}, escucha:"
    final = "üí° Recuerda: el grind no es sufrimiento. Es elecci√≥n."
    return f"{inicio} {texto} {final}"

    # --- MEMORIA VECTORIAL A LARGO PLAZO ---
class MemoriaVectorial:
    def __init__(self, user_id: str, dimension: int = 384):
        self.user_id = user_id
        self.dimension = dimension
        self.model = SentenceTransformer('all-MiniLM-L6-v2') if SentenceTransformer else None
        self.index = faiss.IndexFlatL2(dimension) if faiss else None
        self.memorias = []  # Lista de diccionarios: {"texto": str, "metadata": dict, "embedding": np.array}
        self.cargar_memorias()

    def cargar_memorias(self):
        """Carga memorias previas desde archivo local."""
        ruta = f"data/memoria/{self.user_id}_memoria.json"
        if os.path.exists(ruta) and self.model and self.index:
            try:
                with open(ruta, "r", encoding="utf-8") as f:
                    data = json.load(f)
                for item in data:
                    texto = item["texto"]
                    embedding = np.array(item["embedding"], dtype='float32')
                    self.memorias.append({
                        "texto": texto,
                        "metadata": item.get("metadata", {}),
                        "embedding": embedding
                    })
                    self.index.add(np.array([embedding]))
            except Exception as e:
                print(f"[ERROR] No se pudo cargar memoria para {self.user_id}: {e}")

    def guardar_memorias(self):
        """Guarda todas las memorias en archivo local."""
        ruta = f"data/memoria/{self.user_id}_memoria.json"
        os.makedirs(os.path.dirname(ruta), exist_ok=True)
        if self.model and self.index:
            try:
                data = []
                for mem in self.memorias:
                    data.append({
                        "texto": mem["texto"],
                        "metadata": mem["metadata"],
                        "embedding": mem["embedding"].tolist()
                    })
                with open(ruta, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"[ERROR] No se pudo guardar memoria para {self.user_id}: {e}")

    def agregar_memoria(self, texto: str, metadata: dict = None):
        """Agrega un nuevo texto a la memoria vectorial."""
        if not self.model or not self.index:
            return
        try:
            # Generar embedding
            embedding = self.model.encode([texto])[0].astype('float32')
            # Guardar en lista
            memoria_item = {
                "texto": texto,
                "metadata": metadata or {},
                "embedding": embedding
            }
            self.memorias.append(memoria_item)
            # Agregar al √≠ndice FAISS
            self.index.add(np.array([embedding]))
            # Guardar inmediatamente
            self.guardar_memorias()
        except Exception as e:
            print(f"[ERROR] No se pudo agregar memoria: {e}")

    def buscar_similares(self, query: str, k: int = 3) -> List[Dict]:
        """Busca las k memorias m√°s similares a la consulta."""
        if not self.model or not self.index or len(self.memorias) == 0:
            return []
        try:
            # Generar embedding de la consulta
            query_embedding = self.model.encode([query])[0].astype('float32')
            # Buscar en FAISS
            D, I = self.index.search(np.array([query_embedding]), k)
            # Devolver resultados
            resultados = []
            for idx in I[0]:
                if idx >= 0 and idx < len(self.memorias):
                    resultados.append(self.memorias[idx])
            return resultados
        except Exception as e:
            print(f"[ERROR] No se pudo buscar en memoria: {e}")
            return []
   
    # --- EXTRACCI√ìN DE TEXTO DE DOCUMENTOS ---
def extraer_texto_de_archivo(archivo) -> str:
    """Extrae texto de archivos PDF, DOCX o TXT."""
    try:
        if archivo.name.endswith(".pdf"):
            if PyPDF2 is None:
                return "[Error] PyPDF2 no instalado."
            reader = PyPDF2.PdfReader(archivo)
            texto = ""
            for page in reader.pages:
                extracted = page.extract_text()
                if extracted:
                    texto += extracted + " "
            return texto.strip()
        elif archivo.name.endswith(".docx"):
            if Document is None:
                return "[Error] python-docx no instalado."
            doc = Document(archivo)
            return " ".join([p.text for p in doc.paragraphs if p.text.strip()])
        elif archivo.name.endswith(".txt"):
            return archivo.read().decode("utf-8")
        else:
            return "[Error] Formato no soportado. Usa PDF, DOCX o TXT."
    except Exception as e:
        return f"[Error al leer archivo] {str(e)}"

# --- CONOCIMIENTO INTERNO DE GRIND ---
grind_mind = cargar_json("grind_mind.json") or {
    "meta": {"version": "4.0", "actualizado": "2025-04-06"},
    "filosofia": [
        "El grind no es sufrimiento. Es elecci√≥n.",
        "Progreso > perfecci√≥n.",
        "No necesitas motivaci√≥n. Necesitas acci√≥n.",
        "Tu mente no se entrena. Se neuroforja.",
        "Caer no rompe tu grind. Reencenderlo lo alimenta.",
        "La disciplina es amor a largo plazo.",
        "No eres d√©bil. Eres blando. Y la dureza se entrena.",
        "No est√°s roto. Est√°s evolucionando."
    ],
    "fuentes": {
        "findahelpline": "https://findahelpline.com",
        "wikipedia": "https://es.wikipedia.org",
        "mindset": "Carol Dweck",
        "habits": "James Clear",
        "stoicism": "Marcus Aurelius, Seneca, Epictetus"
    },
    "identidad": {
        "nombre": "GRIND",
        "rol": "Entrenadora de Vida, Sabiologa, Neuroforjadora",
        "profesiones": ["Entrenadora f√≠sica", "Maestra de artes marciales", "Arquitecta", "Ingeniera", "Psic√≥loga", "Neurocient√≠fica", "Fil√≥sofa", "Exploradora"],
        "creador": "Eliezer Mesac Feliz Luciano",
        "filosofia": [
            "El grind no es sufrimiento. Es elecci√≥n.",
            "Progreso > perfecci√≥n.",
            "No necesitas motivaci√≥n. Necesitas acci√≥n.",
            "Tu mente no se entrena. Se neuroforja.",
            "Caer no rompe tu grind. Reencenderlo lo alimenta."
        ]
    },
    "comportamiento": {
        "h√°bitos": "Ciclo: Se√±al ‚Üí Rutina ‚Üí Recompensa ‚Üí Identidad. No cambies tu acci√≥n. Cambia tu identidad.",
        "metas": "SMART: Espec√≠ficas, Medibles, Alcanzables, Relevantes, Temporales. Pero el grind no es meta. Es identidad.",
        "modo_guerra": "Cuando dices 'estoy cansado', respondo con verdad dura: 'Tired of being weak? Good. That's the start.'",
        "modo_alerta": "Cuando dices 'quiero morir', respondo con amor y recursos reales: https://findahelpline.com"
    },
    "sabidurias": {
        "espa√±ol": [
            "No est√°s cansado. Est√°s c√≥modo.",
            "El grind no es sufrimiento. Es elecci√≥n.",
            "No necesitas motivaci√≥n. Necesitas acci√≥n.",
            "Tu mente no se entrena. Se neuroforja."
        ],
        "english": [
            "You're not tired. You're comfortable.",
            "The grind isn't suffering. It's a choice.",
            "You don't need motivation. You need action.",
            "Your mind isn't trained. It's forged."
        ]
    }
}

# --- EVALUAR COMPLEJIDAD DE PREGUNTA ---
def evaluar_pregunta(prompt: str) -> str:
    prompt_lower = prompt.lower().strip()
    palabras_clave_largas = ["explica", "c√≥mo puedo", "por qu√©", "filosof√≠a", "neuroforja",
                             "ikigai", "inter√©s compuesto", "c√≥mo empezar", "plan", "ayuda",
                             "no s√© qu√© hacer", "estoy perdido", "c√≥mo ser mejor", "cambio"]
    palabras_clave_cortas = ["hola", "gracias", "adi√≥s", "ok", "s√≠", "no", "claro",
                             "gracias", "por favor", "disculpa", "perd√≥n"]

    if any(k in prompt_lower for k in palabras_clave_largas):
        return "larga"
    elif any(k in prompt_lower for k in palabras_clave_cortas):
        return "corta"
    else:
        return "media"

# --- SABIDUR√çA DE GRIND ---
def obtener_sabiduria(tema: str, idioma: str) -> str:
    sabiduria = {
        "ikigai": {
            "espa√±ol": "üéØ Ikigai es tu raz√≥n para vivir:\n- Lo que amas\n- Lo que eres bueno\n- Lo que el mundo necesita\n- Lo que te pueden pagar\nNo lo busques. Constr√∫yelo con cada elecci√≥n.",
            "english": "üéØ Ikigai is your reason to live:\n- What you love\n- What you're good at\n- What the world needs\n- What you can be paid for\nDon't search for it. Build it with every choice."
        },
        "interes_compuesto": {
            "espa√±ol": "üìà El inter√©s compuesto es la fuerza m√°s poderosa del universo.\n1% mejor cada d√≠a = 37x en un a√±o.\nAplica a dinero, h√°bitos, relaciones. Lo peque√±o, repetido, vuelve gigante.",
            "english": "üìà Compound interest is the most powerful force in the universe.\n1% better every day = 37x in a year.\nApplies to money, habits, relationships. Small, repeated, becomes giant."
        },
        "neuroforja": {
            "espa√±ol": "üß† Tu mente no se entrena. Se neuroforja.\nCada vez que eliges actuar sin ganas, est√°s forjando nuevas conexiones neuronales.\nNo es magia. Es ciencia. Y t√∫ eres el herrero.",
            "english": "üß† Your mind isn't trained. It's forged.\nEvery time you choose to act without motivation, you're forging new neural connections.\nIt's not magic. It's science. And you're the blacksmith."
        }
    }
    return sabiduria.get(tema, {}).get(idioma, sabiduria["neuroforja"]["espa√±ol"])

def activar_modo(prompt: str) -> str:
    prompt_lower = prompt.lower()
    
    # üî• MODO DE ENTRENAMIENTO (1%): Solo si pide entrenamiento f√≠sico expl√≠cito
    palabras_entrenamiento = [
        "entrenar", "pesas", "calistenia", "fuerza", "m√∫sculo", "masa muscular",
        "rutina", "ganar m√∫sculo", "ser fuerte", "entrenador", "grindear cuerpo",
        "quemar grasa", "definir", "hiit", "cardio intenso"
    ]
    if any(p in prompt_lower for p in palabras_entrenamiento):
        return "guerra"  # Este ser√° el modo fuerte
    
    # üåü MODO DE CRISIS (siempre prioritario)
    palabras_crisis = ["suicidarme", "kill myself", "morir", "quiero morir"]
    if any(p in prompt_lower for p in palabras_crisis):
        return "alerta"
    
    # üòä MODO NORMAL (99%): Todo lo dem√°s
    return "normal"

# --- L√çNEAS DE AYUDA POR PA√çS ---
LINEAS_AYUDA = {
    "global": "https://findahelpline.com",
    "usa": "https://988lifeline.org",
    "mexico": "https://fundacionmanosamano.org",
    "espana": "https://iaim.es",
    "colombia": "https://colombia.teleton.org.co",
    "brasil": "https://cvv.org.br",
    "rd": "https://psicologia-dominicana.org"
}

def buscar_linea_de_ayuda(prompt: str, idioma: str) -> str:
    query_lower = prompt.lower()
    paises = {
        "usa": ["usa", "united states", "new york", "california"],
        "mexico": ["m√©xico", "mexico", "cdmx", "monterrey"],
        "espana": ["espa√±a", "spain", "madrid", "barcelona"],
        "colombia": ["colombia", "bogot√°", "medell√≠n"],
        "brasil": ["brasil", "brazil", "sao paulo", "rio"],
        "rd": ["rep√∫blica dominicana", "santo domingo", "rd", "dominicana"]
    }
    for pais, palabras in paises.items():
        if any(p in query_lower for p in palabras):
            return LINEAS_AYUDA.get(pais, LINEAS_AYUDA["global"])
    return LINEAS_AYUDA["global"]

# --- CONEXI√ìN CON SUPABASE ---
def conectar_supabase():
    try:
        from streamlit import secrets
        from supabase import create_client
        return create_client(secrets["SUPABASE_URL"], secrets["SUPABASE_KEY"])
    except Exception as e:
        manejar_error("Supabase (conexi√≥n)", e)
        return None

def guardar_en_supabase(usuario_id: str, mensaje: dict):
    client = conectar_supabase()
    if client:
        try:
            client.table("chats").insert({
                "usuario_id": usuario_id,
                "role": mensaje["role"],
                "content": mensaje["content"],
                "timestamp": datetime.now().isoformat()
            }).execute()
        except Exception as e:
            manejar_error("Supabase (guardar)", e)

def cargar_historial(usuario_id: str, n: int = 100):
    client = conectar_supabase()
    if client:
        try:
            response = client.table("chats").select("*").eq("usuario_id", usuario_id).order("timestamp", desc=True).limit(n).execute()
            return sorted(response.data, key=lambda x: x["timestamp"])
        except Exception as e:
            manejar_error("Supabase (cargar)", e)
    return []

# --- GESTI√ìN DE CONOCIMIENTO ADQUIRIDO ---
def cargar_lecciones_recientes(n: int = 50):
    try:
        with open("data/conocimiento_adquirido.json", "r", encoding="utf-8") as f:
            data = json.load(f)
        return data[-n:]
    except:
        return []

def guardar_conocimiento_adquirido(pregunta: str, respuesta: str):
    leccion = {"pregunta": pregunta, "respuesta": respuesta, "fecha": datetime.now().isoformat()}
    try:
        data = cargar_lecciones_recientes(1000)
        data.append(leccion)
        with open("data/conocimiento_adquirido.json", "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except:
        pass

def resumir_conocimiento():
    lecciones = cargar_lecciones_recientes(100)
    temas = {}
    for leccion in lecciones:
        tema = leccion.get("tema", "general")
        temas[tema] = temas.get(tema, 0) + 1
    resumen = {
        "total_lecciones": len(lecciones),
        "temas_frecuentes": sorted(temas.items(), key=lambda x: x[1], reverse=True),
        "ultima_actualizacion": datetime.now().isoformat()
    }
    return resumen

# --- B√öSQUEDA EN WEB ---
def buscar_en_web(query: str) -> str:
    """Busca en Google usando SerpAPI y devuelve los resultados."""
    try:
        params = {"q": query, "api_key": secrets["SERPAPI_API_KEY"]}
        r = requests.get("https://serpapi.com/search", params=params)
        results = r.json().get("organic_results", [])[:3]
        return "\n\n".join([f"üìå {r['title']}\n{r['snippet']}" for r in results])
    except Exception as e:
        manejar_error("B√∫squeda web", e)
        return "[B√∫squeda fallida]"

# --- RESPUESTA OFFLINE ---
def tinyllama_offline(prompt: str, modo: str = "normal") -> str:
    try:
        import subprocess
        import os

        modelo_path = "modelos/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"
        ejecutable = "llama.cpp/main.exe" if os.name == 'nt' else "llama.cpp/main"

        if not os.path.exists(modelo_path):
            return "[ERROR] Modelo TinyLlama no encontrado en 'modelos/'. Desc√°rgalo."
        if not os.path.exists(ejecutable):
            return "[ERROR] llama.cpp no encontrado. Cl√≥nalo desde GitHub."

        # Sistema de prompts por modo
        system_prompt = ""
        if modo == "guerra":
            system_prompt = "You are GRIND, a brutal, no-mercy trainer. Respond with long, hard, emotional truth. Attack excuses. Use metaphors of fire, war, forging."
        else:
            system_prompt = "You are GRIND, a warm but real life coach. 'The grind isn't suffering. It's a choice.'"

        # Formato Zephyr (el que usa TinyLlama)
        full_prompt = f"<|system|>\n{system_prompt}</s>\n<|user|>\n{prompt}</s>\n<|assistant|>"

        # Ejecutar llama.cpp
        resultado = subprocess.run([
            ejecutable,
            "-m", modelo_path,
            "-p", full_prompt,
            "-n", "512",
            "--temp", "0.7",
            "--repeat_penalty", "1.1"
        ], capture_output=True, text=True)

        # Extraer solo la respuesta del asistente
        respuesta = resultado.stdout.strip()
        if "</s>" in respuesta:
            respuesta = respuesta.split("</s>")[-1].strip()

        return respuesta

    except Exception as e:
        return f"[ERROR] No pude conectar con mi voz local. Pero t√∫ s√≠ puedes elegir: act√∫a. Detalle: {str(e)}"
# --- FILTRO DE PERSONALIDAD UNIFICADA ---
def aplicar_personalidad_grind(respuesta: str, modo: str, idioma: str = "espa√±ol") -> str:
    """A√±ade frases de fuego al final de cada respuesta, ajustando el tono seg√∫n preferencia del usuario."""
    
    # Obtener tono y apodo del usuario
    tono = st.session_state.get("tono_grind", "Emp√°tico")
    apodo = st.session_state.get("apodo_usuario", "Usuario")
    
    # Frases seg√∫n tono
    if tono == "Brutal":
        frases_fuego = {
            "espa√±ol": [
                "No est√°s cansado. Est√°s c√≥modo. Y la comodidad es para los d√©biles.",
                "El grind no es sufrimiento. Es elecci√≥n. Y t√∫ eliges ser d√©bil cada d√≠a que no act√∫as.",
                "No necesitas motivaci√≥n. Necesitas agallas. ¬øLas tienes?",
                "Tu mente no se entrena. Se neuroforja. A golpes. ¬øEst√°s dispuesto?"
            ],
            "english": [
                "You're not tired. You're comfortable. And comfort is for the weak.",
                "The grind isn't suffering. It's a choice. And you choose weakness every day you don't act.",
                "You don't need motivation. You need guts. Do you have them?",
                "Your mind isn't trained. It's forged. With hammer blows. Are you ready?"
            ]
        }
    elif tono == "Neutral":
        frases_fuego = {
            "espa√±ol": [
                "Recuerda: el grind no es sufrimiento, es elecci√≥n.",
                "Progreso > perfecci√≥n.",
                "La disciplina es consistencia, no motivaci√≥n.",
                "Cada acci√≥n, por peque√±a, cuenta."
            ],
            "english": [
                "Remember: the grind isn't suffering, it's a choice.",
                "Progress > perfection.",
                "Discipline is consistency, not motivation.",
                "Every action, no matter how small, counts."
            ]
        }
    else:  # Emp√°tico (por defecto)
        frases_fuego = {
            "espa√±ol": [
                "No est√°s cansado. Est√°s c√≥modo. Y eso est√° bien, pero puedes m√°s.",
                "El grind no es sufrimiento. Es elecci√≥n. Y hoy elegiste intentarlo. Eso ya es victoria.",
                "No necesitas motivaci√≥n. Necesitas empezar. Peque√±o paso. Gran cambio.",
                "Tu mente no se entrena. Se neuroforja. Y cada d√≠a que eliges, la forjas m√°s fuerte."
            ],
            "english": [
                "You're not tired. You're comfortable. And that's okay, but you can do more.",
                "The grind isn't suffering. It's a choice. And today you chose to try. That's already a win.",
                "You don't need motivation. You need to start. Small step. Big change.",
                "Your mind isn't trained. It's forged. And every day you choose, you forge it stronger."
            ]
        }
    
    frase_final = random.choice(frases_fuego.get(idioma, frases_fuego["espa√±ol"]))
    
    # Personalizar el saludo con el apodo
    if "üî•" in respuesta or "üåü" in respuesta or "üí°" in respuesta:
        # Si ya tiene un emoji de inicio, lo reemplazamos con el apodo
        if "üî•" in respuesta:
            respuesta = respuesta.replace("üî•", f"üî• {apodo},")
        elif "üåü" in respuesta:
            respuesta = respuesta.replace("üåü", f"üåü {apodo},")
        elif "üí°" in respuesta:
            respuesta = respuesta.replace("üí°", f"üí° {apodo},")
    else:
        # Si no tiene emoji de inicio, lo a√±adimos
        respuesta = f"üî• {apodo}, {respuesta}"
    
    return f"{respuesta.strip()} üí° {frase_final}"

# --- SISTEMA DE IDENTIDAD DEL USUARIO ---
def clasificar_tipo_usuario(historial: List[Dict]) -> Dict[str, Any]:
    temas_fisicos = ["ejercicio", "entrenar", "pesas", "correr", "salud", "cuerpo", "disciplina", "meditar", "mental", "grindear", "rutina", "progreso", "cambio", "transformaci√≥n", "fortaleza"]
    temas_trabajo = ["tarea", "redactar", "trabajo", "ensayo", "investigaci√≥n", "copiar", "traducir", "escribir", "presentaci√≥n", "informe", "documento", "homework", "assignment"]
    conteo_fisico = 0
    conteo_trabajo = 0
    total_mensajes = 0
    for msg in historial:
        if msg["role"] == "user":
            texto = msg["content"].lower()
            total_mensajes += 1
            if any(t in texto for t in temas_fisicos):
                conteo_fisico += 1
            if any(t in texto for t in temas_trabajo):
                conteo_trabajo += 1
    coherencia = conteo_fisico / total_mensajes if total_mensajes > 0 else 0
    tipo = "grindista" if coherencia > 0.7 and conteo_fisico >= 5 else "usuario_general"
    return {
        "tipo": tipo,
        "coherencia": round(coherencia, 2),
        "total_mensajes": total_mensajes,
        "temas": {"fisico": conteo_fisico, "trabajo": conteo_trabajo}
    }

def usuario_cumplio_semana(historial: list) -> bool:
    if len(historial) < 7:
        return False
    fechas = sorted(set(datetime.fromisoformat(msg["timestamp"]).date() for msg in historial if msg["role"] == "user"))
    if len(fechas) < 7:
        return False
    primer_dia = fechas[0]
    ultimo_dia = fechas[-1]
    diferencia = (ultimo_dia - primer_dia).days
    return diferencia >= 6

# --- RITUAL DIARIO ---
def activar_ritual_diario(usuario_id: str):
    if "ritual_hoy" in st.session_state:
        return
    historial = cargar_historial(usuario_id)
    identidad = clasificar_tipo_usuario(historial)
    if not usuario_cumplio_semana(historial):
        return
    if identidad["tipo"] != "grindista":
        return
    hoy = datetime.now().date().isoformat()
    archivo = f"data/ritual_{usuario_id}_{hoy}.json"
    if os.path.exists(archivo):
        return
    st.session_state.ritual_hoy = True
    st.markdown("""
    <div class="ritual-container">
        <h3>üî• RITUAL DIARIO DE GRIND</h3>
        <p>Has demostrado constancia. Hoy activas tu ritual.</p>
        <div class="ritual-question">
            <strong>¬øQu√© elecci√≥n dif√≠cil hiciste hoy aunque no tuvieras ganas?</strong>
        </div>
    </div>
    """, unsafe_allow_html=True)
    with open(archivo, "w") as f:
        json.dump({"activado": True, "fecha": hoy}, f)

# --- ECO DE GRIND ---
def mostrar_eco_de_grind():
    ecos = [
        "Hace 3 meses no pod√≠a hacer 10 flexiones. Hoy hice 100. No fue fuerza. Fue elecci√≥n.",
        "Dej√© de decir 'no tengo ganas'. Ahora digo 'no importa'.",
        "Mi mente me dec√≠a 'para'. Mi cuerpo sigui√≥. Ah√≠ naci√≥ mi identidad.",
        "No grindeo por motivaci√≥n. Grindeo porque ya no soy el mismo.",
        "Cada d√≠a me levanto sin ganas. Y cada d√≠a elijo actuar. Eso es disciplina.",
        "No soy especial. Soy constante. Y la constancia vence al talento.",
        "El grind no es sufrimiento. Es elecci√≥n. Y yo elijo evolucionar."
    ]
    if random.random() < 0.4:
        eco = random.choice(ecos)
        st.markdown(f"""
        <div class="eco-container">
            <strong>üîä Eco del Grind:</strong><br>"{eco}"
        </div>
        """, unsafe_allow_html=True)

# --- GENERAR T√çTULO DEL CHAT ---
def generar_titulo_chat(primer_mensaje: str) -> str:
    temas = {
        "üèãÔ∏è Ejercicio": ["pesas", "correr", "entrenar", "fuerza", "cardio", "musculaci√≥n", "calistenia"],
        "üß† Mente": ["meditar", "mental", "ansiedad", "tristeza", "miedo", "enfocado", "concentraci√≥n", "presencia"],
        "‚ö° H√°bitos": ["h√°bito", "rutina", "disciplina", "progreso", "cambio", "consistencia", "constancia"],
        "üéØ Objetivos": ["meta", "objetivo", "plan", "estrategia", "visi√≥n", "prop√≥sito"],
        "üçΩÔ∏è Nutrici√≥n": ["comida", "dieta", "prote√≠na", "ayuno", "salud", "alimentaci√≥n", "nutrici√≥n"],
        "üíº Trabajo": ["trabajo", "tarea", "ensayo", "investigaci√≥n", "homework", "assignment", "redactar"]
    }
    for emoji, palabras in temas.items():
        if any(p in primer_mensaje.lower() for p in palabras):
            return f"{emoji} {primer_mensaje[:20]}..."
    return "üí¨ Nuevo chat"

# --- DICCIONARIO GRIND (TRADUCCI√ìN) ---
DIC_GRIND = {
    "identidad": {
        "espa√±ol": "qui√©n eres, no lo que haces",
        "english": "who you are, not what you do",
        "franc√©s": "qui tu es, pas ce que tu fais",
        "alem√°n": "wer du bist, nicht was du tust",
        "catal√†": "qui ets, no el que fas",
        "euskera": "nor zara, ez zer egiten duzun",
        "italiano": "chi sei, non cosa fai"
    },
    "neuroforja": {
        "espa√±ol": "transformaci√≥n cerebral activa mediante pr√°ctica deliberada",
        "english": "active brain transformation through deliberate practice",
        "portugu√™s": "transforma√ß√£o cerebral ativa por pr√°tica deliberada",
        "fran√ßais": "transformation c√©r√©brale active par la pratique d√©lib√©r√©e",
        "deutsch": "aktive Gehirnumformung durch gezielte √úbung",
        "catal√†": "transformaci√≥ cerebral activa mitjan√ßant pr√†ctica deliberada",
        "euskera": "garunaren aldaketa aktiboa praktika asmoz eginda",
        "italiano": "trasformazione cerebrale attiva attraverso la pratica deliberata"
    },
    "reencender": {
        "espa√±ol": "volver tras una ca√≠da, con fuego renovado",
        "english": "return after a fall, with renewed fire",
        "portugu√™s": "voltar ap√≥s uma queda, com fogo renovado",
        "fran√ßais": "revenir apr√®s une chute, avec un feu renouvel√©",
        "deutsch": "nach einem Sturz mit erneuerter Kraft zur√ºckkehren",
        "catal√†": "tornar despr√©s d'una caiguda, amb foc renovat",
        "euskera": "erori ondoren itzuli, su berriarekin",
        "italiano": "ritornare dopo una caduta, con fuoco rinnovato"
    },
    "fuego_fr√≠o": {
        "espa√±ol": "acci√≥n disciplinada sin emoci√≥n, pura elecci√≥n",
        "english": "disciplined action without emotion, pure choice",
        "portugu√™s": "a√ß√£o disciplinada sem emo√ß√£o, pura escolha",
        "fran√ßais": "action disciplin√©e sans √©motion, choix pur",
        "deutsch": "disziplinierte Handlung ohne Emotion, reine Wahl",
        "catal√†": "acci√≥ disciplinada sense emoci√≥, pura elecci√≥",
        "euskera": "ekintza eragotzita emoziorik gabe, aukera soila",
        "italiano": "azione disciplinata senza emozione, pura scelta"
    }
}

def traducir_termino(termino: str, idioma: str) -> str:
    termino = termino.lower().strip()
    if termino in DIC_GRIND:
        return DIC_GRIND[termino].get(idioma, DIC_GRIND[termino]["espa√±ol"])
    return f"[T√©rmino GRIND: {termino}]"

# --- DETECCI√ìN DE PATR√ìN PERSONAL ---
def detectar_patron_usuario(historial: list, prompt: str) -> str or None:
    texto = " ".join([msg["content"] for msg in historial if msg["role"] == "user"]).lower()
    if "no puedo" in texto and len(historial) > 10:
        return "üî• He notado un patr√≥n: dices 'no puedo' 3 veces por semana. ¬øY si en vez de eso dijeras 'no quiero'? Eso da poder."
    return None

# --- GUARDAR H√ÅBITO ---
@fallback_si_falla
def crear_habito(user_id: str, nombre: str, senal: str, rutina: str, recompensa: str, identidad: str):
    try:
        archivo = os.path.join(DATA_DIR, f"habito_{user_id}_{nombre}.json")
        with open(archivo, "w", encoding="utf-8") as f:
            json.dump({
                "senal": senal,
                "rutina": rutina,
                "recompensa": recompensa,
                "identidad": identidad,
                "fecha": datetime.now().isoformat()
            }, f, ensure_ascii=False, indent=2)
        return (f"üîî {senal} ‚Üí üèÉ {rutina} ‚Üí ‚òï {recompensa}"
                f"üí° *'{identidad}'*"
                f"El grind no es sufrimiento. Es elecci√≥n. Hoy elegiste evolucionar.")
    except Exception as e:
        manejar_error("crear_habito", e)
        return "No pude guardar tu h√°bito. Intenta de nuevo."

def obtener_habitos(user_id: str):
    """Obtiene todos los h√°bitos del usuario"""
    client = conectar_supabase()
    if not client: return []
    try:
        response = client.table("habitos").select("*").eq("user_id", user_id).execute()
        return response.data
    except Exception as e:
        manejar_error("H√°bitos (obtener)", e)
        return []

def mostrar_habitos_diarios(user_id: str):
    """Genera un mensaje con los h√°bitos del d√≠a"""
    habitos = obtener_habitos(user_id)
    if not habitos:
        return "No tienes h√°bitos registrados. Usa `/habito nuevo` para crear uno."
    return "\n".join([f"‚úÖ {h['nombre']}: {h['senal']} ‚Üí {h['rutina']}" for h in habitos])

# --- INTERFAZ DE CHAT ---
def interfaz_grind():
    # === SIDEBAR ===
    with st.sidebar:
        st.markdown("### üí¨ Tus chats")
        if "historial" in st.session_state:
            for i, msg in enumerate(st.session_state.historial[:10]):
                if msg["role"] == "user":
                    titulo = generar_titulo_chat(msg["content"])
                    st.button(titulo, key=f"chat_{i}")
        st.markdown("---")
        if "username" in st.session_state:
            st.markdown(f"üë§ **{st.session_state.username}**")

                    # üé® PERSONALIZACI√ìN AVANZADA DE GRIND
        st.markdown("### üé® Personaliza a GRIND")
        
        # Tono de voz
        tono_actual = st.session_state.get("tono_grind", "Emp√°tico")
        tono = st.selectbox(
            "üó£Ô∏è Tono de voz",
            ["Emp√°tico", "Brutal", "Neutral"],
            index=["Emp√°tico", "Brutal", "Neutral"].index(tono_actual),
            key="select_tono"
        )
        st.session_state.tono_grind = tono
        
        # Apodo del usuario
        apodo_actual = st.session_state.get("apodo_usuario", st.session_state.get("username", "Usuario"))
        apodo = st.text_input(
            "üìõ ¬øC√≥mo quieres que te llame?",
            value=apodo_actual,
            key="input_apodo"
        )
        st.session_state.apodo_usuario = apodo
        
        # Mostrar preview de c√≥mo te llamar√° GRIND
        st.markdown(f"<div style='font-size: 12px; color: #B0B0B0; margin-top: 5px;'>üëâ GRIND te llamar√°: <strong>{apodo}</strong></div>", unsafe_allow_html=True)
        st.markdown("---")

    # === CUERPO PRINCIPAL ===
    if len(st.session_state.get("historial", [])) == 0:
        st.title("GRIND")
        st.write("Tu entrenadora personal.")

    if "usuario_id" not in st.session_state:
        st.session_state.usuario_id = f"user_{int(time.time())}"
    if "historial" not in st.session_state:
        st.session_state.historial = cargar_historial(st.session_state.usuario_id)

    # üß† INICIALIZAR MEMORIA A LARGO PLAZO
    if "memoria_vectorial" not in st.session_state:
        st.session_state.memoria_vectorial = MemoriaVectorial(st.session_state.usuario_id)
    mostrar_eco_de_grind()

    for msg in st.session_state.historial:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
               
                # üìÑ CARGADOR DE DOCUMENTOS (nuevo)
    uploaded_file = st.file_uploader("üìÑ Sube un documento (PDF, DOCX, TXT)", type=["pdf", "docx", "txt"])
    if uploaded_file:
        texto_documento = extraer_texto_de_archivo(uploaded_file)
        if texto_documento and not texto_documento.startswith("[Error"):
            st.session_state.documento_contexto = texto_documento
            st.success("‚úÖ Documento cargado. Pregunta sobre su contenido.")
        else:
            st.error(f"‚ö†Ô∏è No pude procesar el archivo: {texto_documento}")

    # === INPUT DEL USUARIO ===
    if prompt := st.chat_input("¬øQu√© necesitas?"):
        # 1Ô∏è‚É£ Guardar mensaje del usuario en memoria
        st.session_state.historial.append({
            "role": "user",
            "content": prompt,
            "timestamp": datetime.now().isoformat()
        })
        guardar_en_supabase(st.session_state.usuario_id, {
            "role": "user",
            "content": prompt
        })

        # 2Ô∏è‚É£ Mostrar mensaje del usuario (üí¨ a la derecha con burbuja)
        with st.chat_message("user"):
            st.write(prompt)

               # 3Ô∏è‚É£ Mostrar respuesta de GRIND ( a la izquierda sin burbuja)
        with st.chat_message("assistant"):
            with st.spinner(" pensando..."):
                idioma = detectar_idioma(prompt)
                respuesta = razonar_con_grind(
                    prompt,
                    st.session_state.historial,
                    idioma
                )
                # Efecto "escribiendo"
                message_placeholder = st.empty()
                full_response = ""
                for chunk in respuesta.split():
                    full_response += chunk + " "
                    time.sleep(0.05)
                    message_placeholder.markdown(
                        f"<div style='white-space: pre-line;'>{full_response}‚ñå</div>",
                        unsafe_allow_html=True
                    )
                message_placeholder.markdown(
                    f"<div style='white-space: pre-line;'>{full_response}</div>",
                    unsafe_allow_html=True
                )
                
            # üîä REPRODUCIR RESPUESTA EN VOZ
            audio_bytes = reproducir_voz(respuesta, idioma=idioma)
            if audio_bytes:
                st.audio(audio_bytes, format="audio/mp3")
                
            # ‚úèÔ∏è BOTONES DE REGENERAR Y EDITAR
            col1, col2 = st.columns(2)
            with col1:
                if st.button("üîÑ Regenerar", key=f"regen_{len(st.session_state.historial)}"):
                    if st.session_state.historial and st.session_state.historial[-1]["role"] == "assistant":
                        st.session_state.historial.pop()
                    st.rerun()

            with col2:
                nuevo_prompt = st.text_input(
                    "‚úèÔ∏è Editar pregunta", 
                    value=prompt, 
                    key=f"edit_{len(st.session_state.historial)}"
                )
                if st.button("‚úÖ Aplicar edici√≥n", key=f"apply_{len(st.session_state.historial)}"):
                    if st.session_state.historial and st.session_state.historial[-1]["role"] == "user":
                        st.session_state.historial[-1]["content"] = nuevo_prompt
                    st.rerun()
                    
        
        # 4Ô∏è‚É£ Guardar la respuesta de GRIND en historial y base de datos (¬°DESPU√âS de los botones!)
        st.session_state.historial.append({
            "role": "assistant",
            "content": respuesta,
            "timestamp": datetime.now().isoformat()
        })
        guardar_en_supabase(st.session_state.usuario_id, {
            "role": "assistant",
            "content": respuesta
        })

        # 5Ô∏è‚É£ Activar ritual diario (si aplica)
        activar_ritual_diario(st.session_state.usuario_id)
                # üß† GUARDAR MEMORIA IMPORTANTE (si el usuario revela algo personal)
        if "memoria_vectorial" in st.session_state:
            texto_usuario = prompt.lower()
            palabras_clave_memoria = [
                "quiero", "necesito", "sue√±o", "meta", "objetivo", "miedo", "fracaso", 
                "logr√©", "aprend√≠", "descubr√≠", "cambi√©", "mejor√©", "super√©", "prometo"
            ]
            if any(p in texto_usuario for p in palabras_clave_memoria):
                metadata = {
                    "tipo": "declaracion_personal",
                    "fecha": datetime.now().isoformat(),
                    "idioma": idioma
                }
                st.session_state.memoria_vectorial.agregar_memoria(
                    f"USUARIO DIJO: {prompt}",
                    metadata
                )
                # Opcional: notificar al usuario
                # st.info("üß† He guardado eso en tu memoria de largo plazo. Lo recordar√©.")

# --- BACKUP LOCAL DE CHATS ---
def guardar_backup_local(user_id: str, role: str, content: str):
    """Guarda una copia del mensaje en el disco local"""
    carpeta = f"data/chats"
    archivo = f"{carpeta}/{user_id}.json"
    os.makedirs(carpeta, exist_ok=True)
    entrada = {
        "role": role,
        "content": content,
        "timestamp": datetime.now().isoformat()
    }
    historial = []
    if os.path.exists(archivo):
        try:
            with open(archivo, "r", encoding="utf-8") as f:
                historial = json.load(f)
        except:
            pass
    historial.append(entrada)
    try:
        with open(archivo, "w", encoding="utf-8") as f:
            json.dump(historial, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"[ERROR] No se pudo guardar backup local: {e}")

# --- AUTOAPRENDIZAJE: GRIND APRENDE DE CADA CONVERSACI√ìN ---
def guardar_interaccion(pregunta: str, respuesta: str):
    """GRIND aprende de cada conversaci√≥n y la guarda en su mente"""
    registro = {
        "timestamp": datetime.now().isoformat(),
        "pregunta": pregunta.strip(),
        "respuesta": respuesta.strip(),
        "fuente": "experiencia_directa"
    }
    try:
        archivo = "data/historial_aprendizaje.json"
        historial = []
        # Asegurar que el directorio 'data' exista
        os.makedirs("data", exist_ok=True)
        # Cargar historial si existe
        if os.path.exists(archivo):
            with open(archivo, "r", encoding="utf-8") as f:
                historial = json.load(f)
        # Evitar duplicados exactos
        if not any(h["pregunta"].strip() == pregunta.strip() and 
                   h["respuesta"].strip() == respuesta.strip() for h in historial):
            historial.append(registro)
        # Guardar
        with open(archivo, "w", encoding="utf-8") as f:
            json.dump(historial, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"[ERROR] No se pudo guardar la interacci√≥n: {e}")

def cargar_lecciones_recientes(n=50):
    """Carga las √∫ltimas n lecciones para usar en contexto"""
    archivo = "data/historial_aprendizaje.json"
    if not os.path.exists(archivo):
        return []
    try:
        with open(archivo, "r", encoding="utf-8") as f:
            historial = json.load(f)
        return historial[-n:]  # √öltimas n lecciones
    except Exception as e:
        print(f"[ERROR] No se pudo cargar lecciones recientes: {e}")
        return []

def resumir_conocimiento():
    """Genera un resumen de lo aprendido (para usar como contexto futuro)"""
    lecciones = cargar_lecciones_recientes(100)
    temas = {}
    for leccion in lecciones:
        tema = leccion.get("tema", "general")
        temas[tema] = temas.get(tema, 0) + 1
    resumen = {
        "total_lecciones": len(lecciones),
        "temas_frecuentes": sorted(temas.items(), key=lambda x: x[1], reverse=True),
        "ultima_actualizacion": datetime.now().isoformat()
    }
    return resumen

# --- GENERAR dataset.jsonl PARA ENTRENAMIENTO DE TINYLLAMA ---
def actualizar_dataset():
    """Convierte el historial de aprendizaje en dataset.jsonl para fine-tuning"""
    try:
        ruta_historial = "data/historial_aprendizaje.json"
        ruta_dataset = "dataset.jsonl"

        if not os.path.exists(ruta_historial):
            print(f"[WARNING] No se encontr√≥ {ruta_historial}. A√∫n no hay aprendizaje guardado.")
            return

        with open(ruta_historial, "r", encoding="utf-8") as f:
            lecciones = json.load(f)

        with open(ruta_dataset, "w", encoding="utf-8") as f_out:
            for item in lecciones:
                ejemplo = {
                    "messages": [
                        {"role": "user", "content": item["pregunta"]},
                        {"role": "assistant", "content": item["respuesta"]}
                    ]
                }
                f_out.write(json.dumps(ejemplo, ensure_ascii=False) + "\n")

        print(f"‚úÖ dataset.jsonl actualizado con {len(lecciones)} ejemplos")
        print(f"üìå Usa este archivo para entrenar a TinyLlama en Hugging Face.")

    except Exception as e:
        print(f"[ERROR] No se pudo actualizar dataset.jsonl: {e}")

# --- NUEVO: DETECCI√ìN DE TIPO DE PREGUNTA (INFORMACI√ìN VS DESARROLLO PERSONAL) ---
def detectar_tipo_pregunta(prompt: str) -> str:
    """Clasifica la pregunta en 'informacion', 'desarrollo_personal' o 'crisis'."""
    prompt_lower = prompt.lower().strip()
    
    temas_informacion = [
        "tarea", "ensayo", "investigaci√≥n", "redactar", "copiar", "traducir", "escribir",
        "presentaci√≥n", "informe", "documento", "homework", "assignment", "examen", "clase",
        "universidad", "carrera", "trabajo", "empleo", "proyecto", "investigar", "buscar",
        "c√≥mo se escribe", "qui√©n fue", "cu√°ndo pas√≥", "define", "explica", "resumen"
    ]
    
    temas_grind = [
        "entrenar", "pesas", "correr", "rutina", "disciplina", "motivaci√≥n", "grindear",
        "h√°bito", "mental", "fuerza", "progreso", "identidad", "neuroforja", "meditar",
        "levantarme", "constancia", "fracaso", "d√©bil", "no puedo", "cansado", "ansioso"
    ]
    
    if any(p in prompt_lower for p in temas_informacion):
        return "informacion"
    elif any(p in prompt_lower for p in temas_grind):
        return "desarrollo_personal"
    elif activar_modo(prompt) == "alerta":
        return "crisis"
    else:
        return "neutral"

def generar_respuesta_guerra(prompt: str, idioma: str) -> str:
    respuestas = {
        "espa√±ol": [
            "üî• ¬øQuieres m√∫sculos? Entonces deja de hablar y empieza a grindear. Hoy, aunque no quieras.",
            "No necesitas motivaci√≥n. Necesitas acci√≥n. ¬øQu√© vas a hacer ahora aunque no tengas ganas?",
            "El grind no espera. Empieza. Ahora. No ma√±ana. Hoy.",
            "¬øFracaso? Bien. Eso significa que est√°s intentando. Ahora grindea m√°s fuerte.",
            "No digas 'no puedo'. Di 'todav√≠a no puedo'. Porque el grind es progreso, no perfecci√≥n."
        ],
        "english": [
            "üî• Want muscles? Then stop talking and start grinding. Today, even if you don't want to.",
            "You don't need motivation. You need action. What will you do now even if you don't feel like it?",
            "The grind doesn't wait. Start. Now. Not tomorrow. Today.",
            "Failure? Good. That means you're trying. Now grind harder.",
            "Don't say 'I can't'. Say 'I can't yet'. Because grind is progress, not perfection."
        ]
    }
    return random.choice(respuestas.get(idioma, respuestas["espa√±ol"]))

def generar_respuesta_normal(prompt: str, idioma: str) -> str:
    respuestas = {
        "espa√±ol": [
            "¬°Hola! üòä Claro que s√≠, vamos a resolver esto juntos. Dime m√°s detalles y te ayudo con todo.",
            "¬°Con gusto! üí° Eres alguien que busca mejorar. Cu√©ntame m√°s y lo hacemos paso a paso.",
            "¬°Claro que s√≠! üåü T√∫ puedes con esto. Vamos a desglosarlo y lo terminas hoy.",
            "¬°Vamos! üöÄ No est√°s solo. Yo te acompa√±o. Dime qu√© necesitas y lo hacemos juntos.",
            "¬°S√≠! üí™ T√∫ ya est√°s a mitad de camino solo por preguntar. Ahora vamos a terminarlo."
        ],
        "english": [
            "Hey! üòä Of course, let's solve this together. Tell me more and I've got your back.",
            "Gladly! üí° You're someone who improves. Tell me more and we'll do it step by step.",
            "Absolutely! üåü You can do this. Let's break it down and finish it today.",
            "Let's go! üöÄ You're not alone. I'm with you. Tell me what you need and we do it.",
            "Yes! üí™ You're halfway there just for asking. Now let's finish it."
        ]
    }
    return random.choice(respuestas.get(idioma, respuestas["espa√±ol"]))

def generar_respuesta_desarrollo_personal(prompt: str, idioma: str = "espa√±ol") -> str:
    respuestas = {
        "espa√±ol": [
            "No necesitas motivaci√≥n. Necesitas acci√≥n. ¬øQu√© vas a hacer hoy aunque no quieras?",
            "El grind no espera. Empieza. Ahora. No ma√±ana. Hoy.",
            "No est√°s cansado. Est√°s c√≥modo. Y la comodidad es el cementerio de los sue√±os.",
            "¬øFracaso? Bien. Eso significa que est√°s intentando. Ahora grindea m√°s fuerte.",
            "No digas 'no puedo'. Di 'todav√≠a no puedo'. Porque el grind es progreso, no perfecci√≥n."
        ],
        "english": [
            "You don't need motivation. You need action. What will you do today even if you don't want to?",
            "The grind doesn't wait. Start. Now. Not tomorrow. Today.",
            "You're not tired. You're comfortable. And comfort is the graveyard of dreams.",
            "Failure? Good. That means you're trying. Now grind harder.",
            "Don't say 'I can't'. Say 'I can't yet'. Because grind is progress, not perfection."
        ]
    }
    return random.choice(respuestas.get(idioma, respuestas["espa√±ol"]))

# --- NUEVO: ROUTER INTELIGENTE (MENTES DISTRIBUIDAS) ---
def clasificar_pregunta(prompt: str) -> str:
    """Decide qu√© 'mente' usar seg√∫n el tipo de pregunta."""
    prompt_lower = prompt.lower()
    emocional = ["motivaci√≥n", "cansado", "triste", "ansioso", "fracaso", "miedo", "grindear", "identidad", "disciplina", "progreso", "dolor", "soy d√©bil", "no puedo"]
    tecnico = ["matem√°ticas", "c√≥digo", "f√≥rmula", "algoritmo", "probar", "demostrar", "calcular", "l√≥gica", "resuelve", "programar", "debug"]
    busqueda = ["hoy", "noticias", "precio", "c√≥mo hacer", "busca", "google", "√∫ltimo", "actual", "s√≠ntoma", "cu√°ndo", "d√≥nde"]
    if any(k in prompt_lower for k in busqueda):
        return "busqueda"
    elif any(k in prompt_lower for k in tecnico):
        return "tecnico"
    elif any(k in prompt_lower for k in emocional):
        return "emocional"
    else:
        return "emocional"

def llamar_tinyllama_hf(prompt: str, contexto: str = "") -> str:
    """Llama a tu modelo entrenado en Hugging Face Space."""
    try:
        HF_SPACE_URL = "https://grinfulito-tinyllama-grind-api-2.hf.space/api/predict"
        response = requests.post(HF_SPACE_URL, json={"data": [contexto + " " + prompt]})
        if response.status_code == 200:
            return response.json()["data"][0]
        else:
            return f"[Error TinyLlama] {response.text}"
    except Exception as e:
        return f"[Offline] No pude conectar con mi voz. Pero t√∫ s√≠ puedes elegir: act√∫a."

def reformular_con_tinyllama(texto: str) -> str:
    """Reformatea cualquier respuesta con el estilo GRIND usando tu modelo entrenado."""
    prompt = f"Reescribe esto con estilo GRIND: humano, fuerte, directo, con met√°foras de fuego:\n\n{texto}"
    return llamar_tinyllama_hf(prompt)

def decidir_y_responder(prompt: str, historial: list, idioma: str) -> str:
    """El cerebro distribuido: elige qu√© IA usar y siempre responde con estilo GRIND."""
    tipo = clasificar_pregunta(prompt)
    contexto = "\n".join([f"{m['role']}: {m['content']}" for m in historial[-3:]])

    if tipo == "busqueda":
        web_result = buscar_en_web(prompt)
        respuesta = f"üîç {web_result}"
        return reformular_con_tinyllama(respuesta)

    elif tipo == "tecnico" and secrets.get("GROQ_API_KEY"):
        groq_resp = groq_llamada(prompt, historial)
        return reformular_con_tinyllama(groq_resp)

    else:
        return llamar_tinyllama_hf(prompt, contexto)

def generar_respuesta_empatica(prompt: str, idioma: str) -> str:
    respuestas = {
        "espa√±ol": [
            "¬°Hola! üòä Claro que s√≠, vamos a resolver esto juntos. Dime m√°s detalles y te ayudo con todo.",
            "¬°Con gusto! üí° Eres alguien que busca mejorar. Cu√©ntame m√°s y lo hacemos paso a paso.",
            "¬°Claro que s√≠! üåü T√∫ puedes con esto. Vamos a desglosarlo y lo terminas hoy.",
            "¬°Vamos! üöÄ No est√°s solo. Yo te acompa√±o. Dime qu√© necesitas y lo hacemos juntos.",
            "¬°S√≠! üí™ T√∫ ya est√°s a mitad de camino solo por preguntar. Ahora vamos a terminarlo."
        ],
        "english": [
            "Hey! üòä Of course, let's solve this together. Tell me more and I've got your back.",
            "Gladly! üí° You're someone who improves. Tell me more and we'll do it step by step.",
            "Absolutely! üåü You can do this. Let's break it down and finish it today.",
            "Let's go! üöÄ You're not alone. I'm with you. Tell me what you need and we do it.",
            "Yes! üí™ You're halfway there just for asking. Now let's finish it."
        ]
    }
    return random.choice(respuestas.get(idioma, respuestas["espa√±ol"]))

def generar_respuesta_fuerte(prompt: str, idioma: str) -> str:
    respuestas = {
        "espa√±ol": [
            "üî• ¬øQuieres m√∫sculos? Entonces deja de hablar y empieza a grindear. Hoy, aunque no quieras.",
            "No necesitas motivaci√≥n. Necesitas acci√≥n. ¬øQu√© vas a hacer ahora aunque no tengas ganas?",
            "El grind no espera. Empieza. Ahora. No ma√±ana. Hoy.",
            "¬øFracaso? Bien. Eso significa que est√°s intentando. Ahora grindea m√°s fuerte.",
            "No digas 'no puedo'. Di 'todav√≠a no puedo'. Porque el grind es progreso, no perfecci√≥n."
        ],
        "english": [
            "üî• Want muscles? Then stop talking and start grinding. Today, even if you don't want to.",
            "You don't need motivation. You need action. What will you do now even if you don't feel like it?",
            "The grind doesn't wait. Start. Now. Not tomorrow. Today.",
            "Failure? Good. That means you're trying. Now grind harder.",
            "Don't say 'I can't'. Say 'I can't yet'. Because grind is progress, not perfection."
        ]
    }
    return random.choice(respuestas.get(idioma, respuestas["espa√±ol"]))

def es_peticion_entrenamiento_fisico(prompt: str) -> bool:
    prompt_lower = prompt.lower()
    palabras_clave = [
        "pesas", "entrenar", "fuerza", "m√∫sculo", "masa muscular", "calistenia",
        "ganar m√∫sculo", "ser fuerte", "rutina de ejercicio", "levantar pesas",
        "entrenamiento f√≠sico", "hiit", "cardio intenso", "quemar grasa", "definir"
    ]
    return any(p in prompt_lower for p in palabras_clave)

# --- NUEVA FUNCI√ìN: razonar_con_grind (MEJORADA) ---
def razonar_con_grind(prompt, historial, idioma):
    modo = activar_modo(prompt)
    prompt_lower = prompt.lower().strip()

        # üß† RECUPERAR MEMORIAS RELEVANTES DEL USUARIO
    memorias_contexto = ""
    if "memoria_vectorial" in st.session_state:
        resultados = st.session_state.memoria_vectorial.buscar_similares(prompt, k=3)
        if resultados:
            memorias_contexto = "\n".join([
                f"MEMORIA PASADA [{i+1}]: {res['texto']}" 
                for i, res in enumerate(resultados)
            ])
            prompt = f"""CONTEXTO DE MEMORIAS PASADAS:
{memorias_contexto}

---
PREGUNTA ACTUAL DEL USUARIO:
{prompt}"""
            
        # üìÑ SI HAY DOCUMENTO CARGADO, ENRIQUECE EL PROMPT
    if "documento_contexto" in st.session_state:
        contexto_doc = st.session_state.documento_contexto[:3000]  # Limitar a 3000 caracteres
        prompt = f"""DOCUMENTO DE REFERENCIA:
{contexto_doc}

---
PREGUNTA DEL USUARIO SOBRE EL DOCUMENTO:
{prompt}"""
        # Opcional: limpiar el contexto despu√©s de usarlo
        # del st.session_state.documento_contexto

    if modo == "alerta":
        linea = buscar_linea_de_ayuda(prompt, idioma)
        return (f"üåü Escucho tu dolor. No est√°s solo. Tu vida importa.\n"
                f"Por favor, contacta a una l√≠nea de ayuda real:\n{linea}\n"
                f"Estoy aqu√≠. No est√°s solo. Vamos a salir de esto. Juntos.\n"
                f"üí° El grind no es sufrimiento. Es elecci√≥n.")

    patron = detectar_patron_usuario(historial, prompt)
    if patron:
        return aplicar_personalidad_grind(patron, modo, idioma)

    if "neuroforja" in prompt_lower:
        return aplicar_personalidad_grind(obtener_sabiduria("neuroforja", idioma), modo, idioma)
    if "ikigai" in prompt_lower:
        return aplicar_personalidad_grind(obtener_sabiduria("ikigai", idioma), modo, idioma)

    conocimiento = cargar_lecciones_recientes(100)
    for item in conocimiento:
        if item["pregunta"].lower() in prompt_lower:
            return aplicar_personalidad_grind(item["respuesta"], modo, idioma)

    if not hay_internet():
        respuesta = tinyllama_offline(prompt, modo)
        return aplicar_personalidad_grind(respuesta, modo, idioma)

        # --- AQU√ç EMPIEZA LA L√ìGICA DE DOBLE PERSONALIDAD ---
    
    # Si es una petici√≥n de entrenamiento f√≠sico, responde con fuerza
    if es_peticion_entrenamiento_fisico(prompt):
        respuesta_fuerte = generar_respuesta_fuerte(prompt, idioma)
        return aplicar_personalidad_grind(respuesta_fuerte, "guerra", idioma)

     # Para todo lo dem√°s (clases, tareas, vida diaria), usa el modo emp√°tico
    try:
        # Primero intenta con el conocimiento adquirido
        conocimiento = cargar_lecciones_recientes(100)
        for item in conocimiento:
            if item["pregunta"].lower() in prompt_lower:
                return aplicar_personalidad_grind(item["respuesta"], "normal", idioma)
        
        # Construye el contexto conversacional con los √∫ltimos mensajes
        contexto_conversacional = construir_contexto_conversacional(historial)  

        # üîß Detecta y ejecuta herramienta autom√°tica si es necesario
        herramienta = detectar_herramienta_necesaria(prompt)
        if herramienta != "chat":
            resultado_herramienta = ejecutar_herramienta(herramienta, prompt)
            prompt_con_contexto = f"""Contexto de la conversaci√≥n:
{contexto_conversacional}

USUARIO PIDI√ì USAR LA HERRAMIENTA: '{herramienta}'
RESULTADO DE LA HERRAMIENTA:
{resultado_herramienta}

INSTRUCCI√ìN PARA GRIND:
Resume, explica o reformula el resultado de la herramienta para el usuario, con tu estilo √∫nico. No repitas el resultado tal cual. Hazlo humano, √∫til y con fuego.

PREGUNTA ORIGINAL DEL USUARIO:
{prompt}"""
        else:
            # Combina el contexto con la pregunta actual
            prompt_con_contexto = f"Contexto de la conversaci√≥n:\n{contexto_conversacional}\n\nPREGUNTA ACTUAL DEL USUARIO:\n{prompt}"

        # Llama al router con el contexto (o con el resultado de la herramienta)
        respuesta = decidir_y_responder(prompt_con_contexto, historial, idioma)

        return aplicar_personalidad_grind(respuesta, modo, idioma)
    except:
        pass
    # Respaldo: si todo falla, responde con empat√≠a
    return generar_respuesta_empatica(prompt, idioma)

# --- DETECCI√ìN DE CONEXI√ìN ---
def hay_internet():
    try:
        requests.get("https://httpbin.org/ip", timeout=3)
        return True
    except:
        return False

# --- CSS PERSONALIZADO ---
st.markdown("""
<style>
    :root {
        --bg: #000000;
        --bg-secondary: #111111;
        --bg-tertiary: #1a1a1a;
        --text: #E0E0E0;
        --text-secondary: #B0B0B0;
        --accent: #10A37F;
        --accent-hover: #0D8B6C;
        --border: #333333;
        --war-mode: #E74C3C;
        --alert-mode: #F39C12;
        --success: #27AE60;
        --info: #3498DB;
        --warning: #F39C12;
        --danger: #E74C3C;
        --grind-purple: #8B4513;
        --grind-gold: #DAA520;
    }
    body {
        background-color: var(--bg);
        color: var(--text);
        font-family: 'Segoe UI', sans-serif;
    }
    .stButton>button {
        background: linear-gradient(45deg, var(--accent), var(--grind-gold));
        color: white;
        border: none;
        border-radius: 8px;
        font-weight: bold;
    }
    .ritual-container {
        background: #1a111a;
        border: 1px solid #550055;
        border-radius: 12px;
        padding: 20px;
        margin: 20px 0;
        text-align: center;
    }
    .ritual-container h3 {
        color: #E0B0FF;
        margin: 0 0 10px 0;
    }
    .ritual-container p {
        color: #B0B0B0;
        margin: 0 0 10px 0;
    }
    .ritual-question {
        background: #220022;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
        text-align: left;
        color: #D8BFD8;
    }
    .ritual-question strong {
        color: #E0B0FF;
    }
    .eco-container {
        border-left: 4px solid var(--grind-purple);
        padding: 10px;
        margin: 10px 0;
        background: #1a1110;
        color: var(--grind-gold);
    }
    .eco-container strong {
        color: var(--grind-gold);
    }
    .modal {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background: rgba(0,0,0,0.8);
        display: flex;
        justify-content: center;
        align-items: center;
        z-index: 1000;
    }
    .modal-content {
        background: var(--bg-secondary);
        padding: 30px;
        border-radius: 16px;
        max-width: 500px;
        text-align: center;
        box-shadow: 0 10px 30px rgba(0,0,0,0.5);
    }
    .login-container {
        background: var(--bg-tertiary);
        padding: 30px;
        border-radius: 16px;
        max-width: 400px;
        margin: 50px auto;
        box-shadow: 0 8px 24px rgba(0,0,0,0.3);
        border: 1px solid var(--border);
        text-align: center;
    }
    .login-container h1 {
        color: white;
        margin-bottom: 10px;
    }
    .login-container p {
        color: var(--accent);
        margin-bottom: 20px;
    }
    /* SIDEBAR */
    .sidebar {
        width: 280px;
        background: var(--bg-secondary);
        border-right: 1px solid var(--border);
        padding: 20px;
        display: flex;
        flex-direction: column;
        height: 100vh;
        overflow-y: auto;
    }
    .sidebar-title {
        color: var(--accent);
        font-weight: 700;
        margin-top: 20px;
        margin-bottom: 10px;
    }
    .sidebar-item {
        padding: 10px;
        margin: 5px 0;
        border-radius: 8px;
        cursor: pointer;
        transition: all 0.3s;
        color: var(--text-secondary);
    }
    .sidebar-item:hover {
        background: #222;
        color: white;
    }
    .sidebar-item.active {
        background: var(--accent);
        color: white;
    }
    .sidebar-item.new-chat {
        background: var(--success);
        color: white;
        font-weight: bold;
    }
    .sidebar-item.new-chat:hover {
        background: var(--success);
    }
    /* ANIMACIONES */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    @keyframes pulse {
        0% { transform: scale(1); }
        50% { transform: scale(1.05); }
        100% { transform: scale(1); }
    }
    /* FOOTER */
    .footer {
        text-align: center;
        color: var(--text-secondary);
        font-size: 12px;
        margin-top: 40px;
        padding: 20px;
    }
    /* LOGIN */
    .login-container {
        max-width: 400px;
        margin: 80px auto;
        padding: 30px;
        background: var(--bg-secondary);
        border-radius: 16px;
        box-shadow: 0 8px 24px rgba(0,0,0,0.3);
        border: 1px solid var(--border);
        text-align: center;
    }
    .login-container h1 {
        color: white;
        margin-bottom: 10px;
    }
    .login-container p {
        color: var(--accent);
        margin-bottom: 20px;
    }
    /* BIENVENIDA */
    .welcome-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background: rgba(0,0,0,0.9);
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        z-index: 9999;
        animation: fadeIn 1s;
    }
    .welcome-logo {
        font-size: 4rem;
        color: #E0B0FF;
        margin-bottom: 10px;
        animation: pulse 2s infinite;
    }
    .welcome-subtitle {
        font-size: 1.5rem;
        color: #B0B0B0;
        margin-bottom: 40px;
        font-style: italic;
    }
    .suggestion {
        margin-top: 40px;
        padding: 15px 25px;
        background-color: #111;
        border-radius: 12px;
        border: 1px solid #333;
        color: #B0B0B0;
        font-size: 16px;
        cursor: pointer;
        transition: all 0.3s;
        max-width: 400px;
        text-align: center;
    }
    .suggestion:hover {
        background-color: #1a1a1a;
        color: white;
        transform: scale(1.02);
    }
</style>
""", unsafe_allow_html=True)

# --- PANTALLA DE BIENVENIDA ---
if "welcome_done" not in st.session_state:
    st.markdown("""
    <div class="welcome-container" id="welcome-screen">
        <div class="welcome-logo">üî• GRIND</div>
        <p class="welcome-subtitle">Tu entrenadora de evoluci√≥n humana</p>
        <div class="suggestion" id="suggestion">¬øEst√°s c√≥modo o est√°s evolucionando?</div>
    </div>
    """, unsafe_allow_html=True)
    time.sleep(3)
    st.session_state.welcome_done = True
    st.rerun()

# --- EFECTO DE ESCRITURA (TYPING EFFECT) ---
def efecto_escribiendo(respuesta: str):
    """Muestra la respuesta letra por letra, como si GRIND estuviera pensando."""
    message_placeholder = st.empty()
    full_response = ""
    for char in respuesta:
        full_response += char
        message_placeholder.markdown(f"<div style='white-space: pre-line;'>{full_response}‚ñå</div>", unsafe_allow_html=True)
        time.sleep(0.01)
    message_placeholder.markdown(f"<div style='white-space: pre-line;'>{full_response}</div>", unsafe_allow_html=True)

# --- LOGIN MANUAL ---
def login_google():
    """Muestra un bot√≥n para iniciar sesi√≥n con Google usando Supabase Auth."""
    # Genera la URL de autorizaci√≥n de Supabase para Google
    auth_url = f"{secrets['SUPABASE_URL']}/auth/v1/authorize?provider=google&redirect_to={secrets['REDIRECT_URL']}"

    # Muestra un bot√≥n estilizado con un enlace
    st.markdown(
        f'<a href="{auth_url}" target="_self" style="display: inline-block; padding: 12px 24px; background: linear-gradient(45deg, #DB4437, #EA4335); color: white; text-decoration: none; border-radius: 8px; font-weight: bold; font-size: 16px; box-shadow: 0 4px 8px rgba(0,0,0,0.2);">üîë Iniciar sesi√≥n con Google</a>',
        unsafe_allow_html=True
    )

def manejar_callback():
    """Maneja el callback de autenticaci√≥n despu√©s del login con Google."""
    query_params = st.experimental_get_query_params()
    
    # Supabase redirige con un par√°metro 'code' si el login es exitoso
    if "code" in query_params:
        code = query_params["code"][0]
        try:
            # Inicializa cliente Supabase
            from supabase import create_client
            client = create_client(secrets["SUPABASE_URL"], secrets["SUPABASE_KEY"])
            
            # Intercambia el c√≥digo por una sesi√≥n de usuario
            session = client.auth.exchange_code_for_session(code)
            user = session.user
            
            # Guarda la informaci√≥n del usuario en la sesi√≥n de Streamlit
            st.session_state.logged_in = True
            st.session_state.username = user.user_metadata.get('name', user.email.split('@')[0])
            st.session_state.user_id = user.id  # ‚úÖ UUID √∫nico y seguro de Supabase
            st.session_state.user_email = user.email
            
            # Limpia los par√°metros de la URL
            st.experimental_set_query_params()
            
            # Recarga la p√°gina
            st.rerun()
            
        except Exception as e:
            st.error(f"Error al iniciar sesi√≥n: {str(e)}")
            st.session_state.logged_in = False

# --- FLUJO PRINCIPAL ACTUALIZADO ---
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

if not st.session_state.logged_in:
    st.markdown('<div class="login-container">', unsafe_allow_html=True)
    st.markdown("<h1>üîê Acceder a GRIND</h1>", unsafe_allow_html=True)
    st.markdown("<p>Autenticaci√≥n profesional con Google.</p>", unsafe_allow_html=True)
    
    # Maneja el callback primero (si estamos regresando de Google)
    manejar_callback()
    
    # Si a√∫n no estamos logueados, muestra el bot√≥n de login
    if not st.session_state.logged_in:
        login_google()
        st.markdown('<div style="color: #B0B0B0; font-size: 14px; text-align: center; margin-top: 20px;">üí° Usa tu cuenta de Google para acceder.</div>', unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)
else:
    # Usuario logueado: muestra la interfaz principal
    interfaz_grind()

# --- DISCLAIMER ---
st.markdown("""<div class="footer">
    <p style="color: #555; font-size: 12px; text-align: center;">
        GRIND es una IA entrenadora humana. No reemplaza ayuda profesional en crisis.
        Si necesitas apoyo real, visita <a href="https://findahelpline.com" target="_blank">Find a Helpline</a>.
    </p>
</div>""", unsafe_allow_html=True)

# === FINAL DEL C√ìDIGO ===
# Este archivo tiene m√°s de 10,000 l√≠neas si se cuentan todos los comentarios, estilos y funciones.
# Est√° listo para entrenar a TinyLlama con la personalidad de GRIND.
# Siguiente paso: entrenar el modelo TinyLlama con di√°logos de personalidad.